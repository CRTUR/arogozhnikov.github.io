{"version":3,"sources":["gradient_boosting.js"],"names":[],"mappings":"AAAA;;;;;;IAEM,qB;;;AAEF,mCAAY,CAAZ,EAAe,CAAf,EAAkB,SAAlB,EAA6B;AAAA;;AACzB,YAAI,aAAa,CAAb,IAAkB,EAAE,MAAF,GAAW,CAAjC,EAAoC;AAChC,iBAAK,OAAL,GAAe,IAAf;AACA,iBAAK,eAAL,GAAuB,EAAE,MAAF,CAAS,UAAC,CAAD,EAAI,CAAJ;AAAA,uBAAU,IAAI,CAAd;AAAA,aAAT,EAA0B,CAA1B,IAA+B,EAA/B,GAAoC,EAAE,MAA7D;AACH,SAHD,MAGO;AACH,iBAAK,OAAL,GAAe,KAAf;AACA,gBAAI,kBAAkB,sBAAsB,qBAAtB,CAA4C,CAA5C,EAA+C,CAA/C,CAAtB;AACA,iBAAK,aAAL,GAAqB,gBAAgB,CAAhB,CAArB;AACA,iBAAK,WAAL,GAAmB,gBAAgB,CAAhB,CAAnB;AACA,gBAAI,SAAS,EAAb;AACA,gBAAI,SAAS,EAAb;AACA,gBAAI,UAAU,EAAd;AACA,gBAAI,UAAU,EAAd;;AAEA,iBAAK,IAAI,WAAW,CAApB,EAAuB,WAAW,EAAE,MAApC,EAA4C,UAA5C,EAAwD;AACpD,oBAAI,UAAU,EAAE,QAAF,CAAd;AACA,oBAAI,UAAU,EAAE,QAAF,CAAd;AACA,oBAAI,KAAK,eAAL,CAAqB,OAArB,KAAiC,CAArC,EAAwC;AACpC,4BAAQ,IAAR,CAAa,OAAb;AACA,4BAAQ,IAAR,CAAa,OAAb;AACH,iBAHD,MAGO;AACH,2BAAO,IAAP,CAAY,OAAZ;AACA,2BAAO,IAAP,CAAY,OAAZ;AACH;AACJ;AACD,iBAAK,UAAL,GAAkB,IAAI,qBAAJ,CAA0B,MAA1B,EAAkC,MAAlC,EAA0C,YAAY,CAAtD,CAAlB;AACA,iBAAK,WAAL,GAAmB,IAAI,qBAAJ,CAA0B,OAA1B,EAAmC,OAAnC,EAA4C,YAAY,CAAxD,CAAnB;AACH;AACJ;;;;wCAEe,C,EAAG;AACf,mBAAO,EAAE,KAAK,aAAP,IAAwB,KAAK,WAA7B,GAA2C,CAA3C,GAA+C,CAAtD;AACH;;;wCAEe,C,EAAG;AACf,gBAAI,KAAK,OAAT,EAAkB;AACd,uBAAO,CAAP;AACH;AACD,gBAAI,KAAK,eAAL,CAAqB,CAArB,KAA2B,CAA/B,EAAkC;AAC9B,uBAAO,IAAI,KAAK,WAAL,CAAiB,eAAjB,CAAiC,CAAjC,CAAJ,GAA0C,CAAjD;AACH,aAFD,MAEO;AACH,uBAAO,IAAI,KAAK,UAAL,CAAgB,eAAhB,CAAgC,CAAhC,CAAX;AACH;AACJ;;;0CAEiB,C,EAAG;AACjB,gBAAI,KAAK,OAAT,EAAkB;AACd,uBAAO,KAAK,eAAZ;AACH;AACD,gBAAI,KAAK,eAAL,CAAqB,CAArB,KAA2B,CAA/B,EAAkC;AAC9B,uBAAO,KAAK,WAAL,CAAiB,iBAAjB,CAAmC,CAAnC,CAAP;AACH,aAFD,MAEO;AACH,uBAAO,KAAK,UAAL,CAAgB,iBAAhB,CAAkC,CAAlC,CAAP;AACH;AACJ;;;8CAE4B,C,EAAG,C,EAAG;AAC/B,gBAAI,QAAQ,EAAE,MAAF,CAAS,UAAC,CAAD,EAAI,CAAJ;AAAA,uBAAU,IAAI,CAAd;AAAA,aAAT,EAA0B,EAA1B,CAAZ;AACA,gBAAI,YAAY,CAAC,CAAjB;AACA,gBAAI,eAAe,CAAnB;AACA,gBAAI,aAAa,CAAC,GAAlB;;AAEA,iBAAK,IAAI,UAAU,CAAnB,EAAsB,UAAU,CAAhC,EAAmC,SAAnC,EAA8C;AAC1C,oBAAI,qBAAqB,EAAzB;AACA,qBAAK,IAAI,WAAW,CAApB,EAAuB,WAAW,EAAE,MAApC,EAA4C,UAA5C,EAAwD;AACpD,uCAAmB,IAAnB,CAAwB,CAAC,EAAE,QAAF,EAAY,OAAZ,CAAD,EAAuB,EAAE,QAAF,CAAvB,CAAxB;AACH;AACD,qCAAqB,mBAAmB,IAAnB,CAAwB,UAAC,CAAD,EAAI,CAAJ;AAAA,2BAAU,EAAE,CAAF,IAAO,EAAE,CAAF,CAAjB;AAAA,iBAAxB,CAArB;;AAEA,oBAAI,WAAW,EAAf;;AAEA,qBAAK,IAAI,YAAW,CAApB,EAAuB,YAAW,mBAAmB,MAAnB,GAA4B,CAA9D,EAAiE,WAAjE,EAA6E;AACzE,gCAAY,mBAAmB,SAAnB,EAA6B,CAA7B,CAAZ;AACA,wBAAI,YAAY,QAAQ,QAAxB;AACA,wBAAI,gBAAgB,YAAW,CAA/B;AACA,wBAAI,iBAAiB,mBAAmB,MAAnB,GAA4B,aAAjD;;AAEA,wBAAI,OAAO,WAAW,QAAX,GAAsB,aAAtB,GAAsC,YAAY,SAAZ,GAAwB,cAAzE;AACA,4BAAQ,KAAK,MAAL,KAAgB,IAAxB;AACA,wBAAI,OAAO,SAAX,EAAsB;AAClB,oCAAY,IAAZ;AACA,uCAAe,OAAf;AACA,qCAAa,CAAC,mBAAmB,SAAnB,EAA6B,CAA7B,IAAkC,mBAAmB,YAAW,CAA9B,EAAiC,CAAjC,CAAnC,IAA0E,EAAvF;AACH;AACJ;AACJ;AACD,mBAAO,CAAC,YAAD,EAAe,UAAf,CAAP;AACH;;;;;;IAGC,yB;AACF,uCAAY,CAAZ,EAAe,CAAf,EAAkB,YAAlB,EAAgC,SAAhC,EAA2C,aAA3C,EAA0D;AAAA;;AACtD,aAAK,SAAL,GAAiB,SAAjB;AACA,aAAK,aAAL,GAAqB,aAArB;AACA,aAAK,KAAL,GAAa,EAAb;;AAEA,YAAI,oBAAoB,IAAI,KAAJ,CAAU,EAAE,MAAZ,EAAoB,IAApB,CAAyB,EAAzB,CAAxB;;AAEA,aAAK,IAAI,UAAU,CAAnB,EAAsB,UAAU,YAAhC,EAA8C,SAA9C,EAAyD;AACrD,gBAAI,SAAS,MAAM,EAAE,MAAR,CAAb;AACA,iBAAK,IAAI,WAAW,CAApB,EAAuB,WAAW,EAAE,MAApC,EAA4C,UAA5C,EAAwD;AACpD,uBAAO,QAAP,IAAmB,EAAE,QAAF,IAAc,kBAAkB,QAAlB,CAAjC;AACH;AACD,gBAAI,WAAW,IAAI,qBAAJ,CAA0B,CAA1B,EAA6B,MAA7B,EAAqC,KAAK,SAA1C,CAAf;AACA,iBAAK,KAAL,CAAW,IAAX,CAAgB,QAAhB;;AAEA,iBAAK,IAAI,aAAW,CAApB,EAAuB,aAAW,EAAE,MAApC,EAA4C,YAA5C,EAAwD;AACpD,kCAAkB,UAAlB,KAA+B,gBAAgB,SAAS,iBAAT,CAA2B,EAAE,UAAF,CAA3B,CAA/C;AACH;AACJ;AACJ;;;;0CAEiB,C,EAAG,O,EAAS;AAC1B,sBAAU,WAAW,KAAK,KAAL,CAAW,MAAhC;AACA,gBAAI,aAAa,CAAjB;AACA,iBAAK,IAAI,UAAU,CAAnB,EAAsB,UAAU,OAAhC,EAAyC,SAAzC,EAAoD;AAChD,8BAAc,KAAK,aAAL,GAAqB,KAAK,KAAL,CAAW,OAAX,EAAoB,iBAApB,CAAsC,CAAtC,CAAnC;AACH;AACD,mBAAO,UAAP;AACH;;;;;;IAIC,0B;AACF,wCAAY,CAAZ,EAAe,CAAf,EAAkB,YAAlB,EAAgC,SAAhC,EAA2C,aAA3C,EAAuF;AAAA,YAA7B,oBAA6B,yDAAN,IAAM;;AAAA;;AACnF,aAAK,SAAL,GAAiB,SAAjB;AACA,aAAK,aAAL,GAAqB,aAArB;AACA,aAAK,KAAL,GAAa,EAAb;AACA,aAAK,oBAAL,GAA4B,oBAA5B;;AAEA,YAAI,oBAAoB,IAAI,KAAJ,CAAU,EAAE,MAAZ,EAAoB,IAApB,CAAyB,EAAzB,CAAxB;;AAEA,aAAK,IAAI,UAAU,CAAnB,EAAsB,UAAU,YAAhC,EAA8C,SAA9C,EAAyD;AACrD,gBAAI,SAAS,MAAM,EAAE,MAAR,CAAb;AACA,iBAAK,IAAI,WAAW,CAApB,EAAuB,WAAW,EAAE,MAApC,EAA4C,UAA5C,EAAwD;AACpD,uBAAO,QAAP,IAAmB,EAAE,QAAF,IAAc,2BAA2B,OAA3B,CAAmC,kBAAkB,QAAlB,CAAnC,CAAjC;AACH;;AAED,gBAAI,SAAS,MAAM,cAAN,CAAqB,CAArB,EAAwB,UAAU,KAAK,oBAAvC,CAAb;AACA,gBAAI,WAAW,IAAI,qBAAJ,CAA0B,MAA1B,EAAkC,MAAlC,EAA0C,KAAK,SAA/C,CAAf;AACA,iBAAK,KAAL,CAAW,IAAX,CAAgB,QAAhB;;AAEA,iBAAK,IAAI,aAAW,CAApB,EAAuB,aAAW,EAAE,MAApC,EAA4C,YAA5C,EAAwD;AACpD,kCAAkB,UAAlB,KAA+B,gBAAgB,SAAS,iBAAT,CAA2B,OAAO,UAAP,CAA3B,CAA/C;AACH;AACJ;AACJ;;;;0CAMiB,C,EAAG,O,EAAS;AAC1B,sBAAU,WAAW,KAAK,KAAL,CAAW,MAAhC;AACA,gBAAI,aAAa,CAAjB;AACA,iBAAK,IAAI,UAAU,CAAnB,EAAsB,UAAU,OAAhC,EAAyC,SAAzC,EAAoD;AAChD,8BAAc,KAAK,aAAL,GAAqB,KAAK,0BAAL,CAAgC,CAAhC,EAAmC,OAAnC,CAAnC;AACH;AACD,mBAAO,2BAA2B,OAA3B,CAAmC,UAAnC,CAAP;AACH;;;mDAE0B,C,EAAG,O,EAAS;AACnC,gBAAI,gBAAgB,MAAM,YAAN,CAAmB,CAAnB,EAAsB,UAAU,KAAK,oBAArC,CAApB;AACA,mBAAO,KAAK,KAAL,CAAW,OAAX,EAAoB,iBAApB,CAAsC,aAAtC,CAAP;AACH;;;+CAEsB,C,EAAG,C,EAAG;AACzB,gBAAI,SAAS,CAAC,KAAK,GAAL,CAAS,CAAT,CAAD,CAAb;AACA,gBAAI,oBAAoB,IAAI,KAAJ,CAAU,EAAE,MAAZ,EAAoB,IAApB,CAAyB,CAAzB,CAAxB;AACA,iBAAK,IAAI,UAAU,CAAnB,EAAsB,UAAU,KAAK,KAAL,CAAW,MAA3C,EAAmD,SAAnD,EAA8D;AAC1D,oBAAI,OAAO,EAAX;;AAEA,qBAAK,IAAI,WAAW,CAApB,EAAuB,WAAW,EAAE,MAApC,EAA4C,UAA5C,EAAwD;AACpD,sCAAkB,QAAlB,KAA+B,KAAK,aAAL,GAAqB,KAAK,0BAAL,CAAgC,EAAE,QAAF,CAAhC,EAA6C,OAA7C,CAApD;AACA,wBAAI,WAAW,IAAI,EAAE,QAAF,CAAJ,GAAkB,CAAjC;AACA,4BAAQ,KAAK,GAAL,CAAS,IAAI,KAAK,GAAL,CAAS,CAAC,QAAD,GAAY,kBAAkB,QAAlB,CAArB,CAAb,CAAR;AACH;AACD,uBAAO,IAAP,CAAY,OAAO,EAAE,MAArB;AACH;AACD,mBAAO,MAAP;AACH;;;gCAhCc,C,EAAG;AACd,mBAAO,MAAM,IAAI,KAAK,GAAL,CAAS,CAAC,CAAV,CAAV,CAAP;AACH","file":"gradient_boosting-compiled.js","sourcesContent":["'use strict';\n\nclass DecisionTreeRegressor {\n    // slow but clear implementation of decision tree.\n    constructor(X, y, max_depth) {\n        if (max_depth == 0 || y.length < 2) {\n            this.is_leaf = true;\n            this.leaf_prediction = y.reduce((a, b) => a + b, 0) * 1. / y.length;\n        } else {\n            this.is_leaf = false;\n            let split_and_value = DecisionTreeRegressor.compute_optimal_split(X, y);\n            this.split_feature = split_and_value[0];\n            this.split_value = split_and_value[1];\n            let X_left = [];\n            let y_left = [];\n            let X_right = [];\n            let y_right = [];\n\n            for (let event_id = 0; event_id < X.length; event_id++) {\n                let event_x = X[event_id];\n                let event_y = y[event_id];\n                if (this.predict_subtree(event_x) == 1) {\n                    X_right.push(event_x);\n                    y_right.push(event_y);\n                } else {\n                    X_left.push(event_x);\n                    y_left.push(event_y);\n                }\n            }\n            this.left_child = new DecisionTreeRegressor(X_left, y_left, max_depth - 1);\n            this.right_child = new DecisionTreeRegressor(X_right, y_right, max_depth - 1);\n        }\n    }\n\n    predict_subtree(x) {\n        return x[this.split_feature] > this.split_value ? 0 : 1;\n    }\n\n    predict_leaf_id(x) {\n        if (this.is_leaf) {\n            return 1;\n        }\n        if (this.predict_subtree(x) == 1) {\n            return 2 * this.right_child.predict_leaf_id(x) + 1;\n        } else {\n            return 2 * this.left_child.predict_leaf_id(x);\n        }\n    }\n\n    predict_one_event(x) {\n        if (this.is_leaf) {\n            return this.leaf_prediction;\n        }\n        if (this.predict_subtree(x) == 1) {\n            return this.right_child.predict_one_event(x);\n        } else {\n            return this.left_child.predict_one_event(x);\n        }\n    }\n\n    static compute_optimal_split(X, y) {\n        let y_sum = y.reduce((a, b) => a + b, 0.);\n        let best_gain = -1;\n        let best_feature = 0;\n        let best_split = -999;\n\n        for (let feature = 0; feature < 2; feature++) {\n            let feature_and_answer = [];\n            for (let event_id = 0; event_id < y.length; event_id++) {\n                feature_and_answer.push([X[event_id][feature], y[event_id]]);\n            }\n            feature_and_answer = feature_and_answer.sort((a, b) => a[0] - b[0]);\n\n            let left_sum = 0.;\n\n            for (let event_id = 0; event_id < feature_and_answer.length - 1; event_id++) {\n                left_sum += feature_and_answer[event_id][1];\n                let right_sum = y_sum - left_sum;\n                let n_events_left = event_id + 1;\n                let n_events_right = feature_and_answer.length - n_events_left;\n\n                let gain = left_sum * left_sum / n_events_left + right_sum * right_sum / n_events_right;\n                gain += Math.random() * 1e-5;\n                if (gain > best_gain) {\n                    best_gain = gain;\n                    best_feature = feature;\n                    best_split = (feature_and_answer[event_id][0] + feature_and_answer[event_id + 1][0]) / 2.\n                }\n            }\n        }\n        return [best_feature, best_split];\n    }\n}\n\nclass GradientBoostingRegressor {\n    constructor(X, y, n_estimators, max_depth, learning_rate) {\n        this.max_depth = max_depth;\n        this.learning_rate = learning_rate;\n        this.trees = [];\n\n        let event_predictions = new Array(y.length).fill(0.);\n\n        for (let tree_id = 0; tree_id < n_estimators; tree_id++) {\n            let target = Array(y.length);\n            for (let event_id = 0; event_id < y.length; event_id++) {\n                target[event_id] = y[event_id] - event_predictions[event_id];\n            }\n            let new_tree = new DecisionTreeRegressor(X, target, this.max_depth);\n            this.trees.push(new_tree);\n\n            for (let event_id = 0; event_id < y.length; event_id++) {\n                event_predictions[event_id] += learning_rate * new_tree.predict_one_event(X[event_id]);\n            }\n        }\n    }\n\n    predict_one_event(x, n_trees) {\n        n_trees = n_trees || this.trees.length;\n        let prediction = 0;\n        for (let tree_id = 0; tree_id < n_trees; tree_id++) {\n            prediction += this.learning_rate * this.trees[tree_id].predict_one_event(x);\n        }\n        return prediction;\n    }\n}\n\n\nclass GradientBoostingClassifier {\n    constructor(X, y, n_estimators, max_depth, learning_rate, use_random_rotations = true) {\n        this.max_depth = max_depth;\n        this.learning_rate = learning_rate;\n        this.trees = [];\n        this.use_random_rotations = use_random_rotations;\n\n        let event_predictions = new Array(y.length).fill(0.);\n\n        for (let tree_id = 0; tree_id < n_estimators; tree_id++) {\n            let target = Array(y.length);\n            for (let event_id = 0; event_id < y.length; event_id++) {\n                target[event_id] = y[event_id] - GradientBoostingClassifier.sigmoid(event_predictions[event_id]);\n            }\n\n            let tree_X = Utils.rotate_dataset(X, tree_id * this.use_random_rotations);\n            let new_tree = new DecisionTreeRegressor(tree_X, target, this.max_depth);\n            this.trees.push(new_tree);\n\n            for (let event_id = 0; event_id < y.length; event_id++) {\n                event_predictions[event_id] += learning_rate * new_tree.predict_one_event(tree_X[event_id]);\n            }\n        }\n    }\n\n    static sigmoid(x) {\n        return 1. / (1 + Math.exp(-x));\n    }\n\n    predict_one_event(x, n_trees) {\n        n_trees = n_trees || this.trees.length;\n        let prediction = 0;\n        for (let tree_id = 0; tree_id < n_trees; tree_id++) {\n            prediction += this.learning_rate * this._predict_one_event_by_tree(x, tree_id);\n        }\n        return GradientBoostingClassifier.sigmoid(prediction);\n    }\n\n    _predict_one_event_by_tree(x, tree_id) {\n        let rotated_event = Utils.rotate_event(x, tree_id * this.use_random_rotations);\n        return this.trees[tree_id].predict_one_event(rotated_event);\n    }\n\n    compute_learning_curve(X, y) {\n        let losses = [Math.log(2)];\n        let event_predictions = new Array(y.length).fill(0);\n        for (let tree_id = 0; tree_id < this.trees.length; tree_id++) {\n            let loss = 0.;\n            //let tree = this.trees[tree_id];\n            for (let event_id = 0; event_id < y.length; event_id++) {\n                event_predictions[event_id] += this.learning_rate * this._predict_one_event_by_tree(X[event_id], tree_id);\n                let signed_y = 2 * y[event_id] - 1;\n                loss += Math.log(1 + Math.exp(-signed_y * event_predictions[event_id]));\n            }\n            losses.push(loss / y.length);\n        }\n        return losses;\n    }\n}\n"]}